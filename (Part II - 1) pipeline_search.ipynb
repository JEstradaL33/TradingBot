{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model selection\n",
    "\n",
    "Now that we have data to train the models, we will search for good pipelines using the TPOT library. The hyperparameters for each pipeline will later be optimized using the hyperopt library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import joblib\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vars = joblib.load('models/filtered_vars.joblib')\n",
    "cutoff_date = joblib.load('models/cutoff_date.joblib')\n",
    "df = pd.read_csv('models/req_data.csv', index_col=0, parse_dates=True).dropna()\n",
    "feats = df.drop(labels=['target'], axis=1)\n",
    "to_predict = df.loc[:, 'target']\n",
    "complete_data = pd.read_csv('models/ohlcv.csv', index_col=0, parse_dates=True)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model by cluster phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following our market structure analysis, we will create a regression model for each cluster in the market structure using the subset of variables filtered during the previous step. We will predict a 7 period rolling mean of the closing price returns.  \n",
    "\n",
    "For model optimization, the TPOT library will be implemented. Pipelines will be evaluated with the pearson correlation coefficient using a 10 split time series cross-validation (to avoid look-ahead bias as we are dealing with time series) in the training set. Best pipelines will then forecast the test set and these forecasts will be used in the trading strategy (not the training set ones).\n",
    "\n",
    "To use pearson correlation as the performance measure for optimizing pipelines, you must replace the gp_deap file in the TPOT library with the gp_deap_sec file located in this repository (more specifically, add lines 40 to 49 and line 484 while commenting the rest of the try block, as in the file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll define the search space for TPOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_config_dict = {\n",
    "\n",
    "    'sklearn.linear_model.ElasticNetCV': {\n",
    "        'l1_ratio': np.arange(0.0, 1.01, 0.05),\n",
    "        'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.ExtraTreesRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'lightgbm.LGBMRegressor':{\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.5],\n",
    "        'num_leaves': np.arange(20, 120, 5),\n",
    "        'min_child_samples': np.arange(5, 50, 5),\n",
    "        'subsample': [0.7, 0.9, 1]  \n",
    "    },\n",
    "    \n",
    "    'sklearn.ensemble.GradientBoostingRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'alpha': [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.AdaBoostRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'loss': [\"linear\", \"square\", \"exponential\"]\n",
    "    },\n",
    "\n",
    "    'sklearn.tree.DecisionTreeRegressor': {\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21)\n",
    "    },\n",
    "\n",
    "    'sklearn.neighbors.KNeighborsRegressor': {\n",
    "        'n_neighbors': range(1, 101),\n",
    "        'weights': [\"uniform\", \"distance\"],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    \n",
    "    'sklearn.neighbors.RadiusNeighborsRegressor': {\n",
    "        'leaf_size': np.arange(10, 60, 10),\n",
    "        'p': [1, 2],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.LassoLarsCV': {\n",
    "        'normalize': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.svm.LinearSVR': {\n",
    "        'loss': [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "        'dual': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'epsilon': [1e-4, 1e-3, 1e-2, 1e-1, 1.]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.RandomForestRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.RidgeCV': {\n",
    "    },\n",
    "    \n",
    "    'xgboost.XGBRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'n_jobs': [1],\n",
    "        'verbosity': [0],\n",
    "        'objective': ['reg:squarederror']\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.SGDRegressor': {\n",
    "        'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'alpha': [0.0, 0.01, 0.001] ,\n",
    "        'learning_rate': ['invscaling', 'constant'] ,\n",
    "        'fit_intercept': [True, False],\n",
    "        'l1_ratio': [0.25, 0.0, 1.0, 0.75, 0.5],\n",
    "        'eta0': [0.1, 1.0, 0.01],\n",
    "        'power_t': [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]\n",
    "    },\n",
    "\n",
    "    # Preprocessors\n",
    "    'sklearn.preprocessing.Binarizer': {\n",
    "        'threshold': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.FastICA': {\n",
    "        'tol': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.cluster.FeatureAgglomeration': {\n",
    "        'linkage': ['ward', 'complete', 'average'],\n",
    "        'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MaxAbsScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.PowerTransformer': {\n",
    "    },\n",
    "    \n",
    "    'sklearn.preprocessing.QuantileTransformer': {\n",
    "    },\n",
    "    \n",
    "    'sklearn.preprocessing.MinMaxScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.Normalizer': {\n",
    "        'norm': ['l1', 'l2', 'max']\n",
    "    },\n",
    "    \n",
    "    'sklearn.preprocessing.KBinsDiscretizer': {\n",
    "        'n_bins': [10, 50, 250, 500, 1000],\n",
    "        'encode': ['ordinal'],\n",
    "        'strategy': ['uniform', 'quantile']\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.Nystroem': {\n",
    "        'kernel': ['rbf', 'cosine', 'chi2', 'laplacian', 'polynomial', 'poly', 'linear', 'additive_chi2', 'sigmoid'],\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05),\n",
    "        'n_components': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.PCA': {\n",
    "        'svd_solver': ['randomized'],\n",
    "        'iterated_power': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.PolynomialFeatures': {\n",
    "        'degree': [2],\n",
    "        'include_bias': [False],\n",
    "        'interaction_only': [False]\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.RBFSampler': {\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.RobustScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.StandardScaler': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.ZeroCount': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.OneHotEncoder': {\n",
    "        'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "        'sparse': [False],\n",
    "        'threshold': [10]\n",
    "    },\n",
    "\n",
    "    # Selectors\n",
    "    'sklearn.feature_selection.SelectFwe': {\n",
    "        'alpha': np.arange(0, 0.05, 0.001),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_regression': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectPercentile': {\n",
    "        'percentile': range(1, 100),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_regression': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.VarianceThreshold': {\n",
    "        'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectFromModel': {\n",
    "        'threshold': np.arange(0, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_lag = ['h_high_close', 'h_low_close', 'h_candle_body', 'h_rsi_13h', 'h_ema_50', 'h_ema_200', 'h_obv10_obv50',\n",
    "              'h_obv50_obv200', 'h_close_ma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, asset returns are highly skewed and have high kurtosis as well. There are some data transformations that can be applied to control this. For this problem, we will test the cube root and arcsin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformations = {'none': [lambda x: x, lambda x: x], 'arsinh': [lambda x: np.arcsinh(x), lambda x: np.sinh(x)],\n",
    "                       'cuberoot': [lambda x: np.cbrt(x), lambda x: x**(3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_predictions = {}\n",
    "# Variables that won't get transformed (these are the categorical ones)\n",
    "do_not_transform = ['h_weekday', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'cluster_mode', 'd_obv10_obv50',\n",
    "                   'd_obv50_obv200', 'd_hc_15davg', 'd_lc_15davg', 'd_cb_15davg', 'd_rsi_13', 'd_ret60d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(n_splits=10, gap=50)\n",
    "tpot_model = TPOTRegressor(generations=10, population_size=25, periodic_checkpoint_folder='checkpoints/', random_state=33, \n",
    "                           verbosity=2, cv=cv, config_dict=regressor_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.052236197785574534\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.052236197785574534\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.052236197785574534\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.052236197785574534\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.052236197785574534\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.05405854415814428\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.05457910161308192\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.05457910161308192\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.05457910161308192\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.05457910161308192\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(QuantileTransformer(KBinsDiscretizer(input_matrix, encode=ordinal, n_bins=500, strategy=uniform)), alpha=0.9, learning_rate=0.01, loss=huber, max_depth=9, max_features=0.05, min_samples_leaf=9, min_samples_split=8, n_estimators=100, subsample=0.3)\n",
      "none 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.1633456626511661\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.182855678405291\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.182855678405291\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.182855678405291\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.182855678405291\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.19794663444619195\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.20003949834726836\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.20003949834726836\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.21312950614370854\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.21312950614370854\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(input_matrix, bootstrap=True, max_features=0.05, min_samples_leaf=15, min_samples_split=15, n_estimators=100)\n",
      "none 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.13395351088854857\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.13395351088854857\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.1373292411921046\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.1373292411921046\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.1373292411921046\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.1566121109699179\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.1566121109699179\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.1592132277562311\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.1592132277562311\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.1592132277562311\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(KBinsDiscretizer(input_matrix, encode=ordinal, n_bins=50, strategy=quantile), bootstrap=True, max_features=0.5, min_samples_leaf=12, min_samples_split=8, n_estimators=100)\n",
      "none 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.14905548407589736\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.17353322307831523\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.17353322307831523\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.17353322307831523\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.17353322307831523\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.17353322307831523\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.17353322307831523\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.17771117926724003\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.17771117926724003\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.17771117926724003\n",
      "\n",
      "Best pipeline: RandomForestRegressor(Normalizer(GradientBoostingRegressor(input_matrix, alpha=0.95, learning_rate=0.5, loss=ls, max_depth=2, max_features=0.7000000000000001, min_samples_leaf=8, min_samples_split=14, n_estimators=100, subsample=0.55), norm=l1), bootstrap=True, max_features=1.0, min_samples_leaf=5, min_samples_split=7, n_estimators=100)\n",
      "arsinh 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.049879233651453886\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.04988466736926878\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.04988466736926878\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.04988466736926878\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.05477470785051934\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.056335188060048405\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.056335188060048405\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.06015583901525355\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.06015583901525355\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.06015583901525355\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=1, min_child_weight=13, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.05, verbosity=0)\n",
      "arsinh 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.17421370906452213\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.17421370906452213\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.18094518836007834\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.1865424929910794\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.1865424929910794\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.19509754964449658\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.19509754964449658\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.19509754964449658\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.19749571949702951\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.2066364058706891\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(GradientBoostingRegressor(Normalizer(QuantileTransformer(input_matrix), norm=l1), alpha=0.85, learning_rate=0.5, loss=quantile, max_depth=10, max_features=0.9000000000000001, min_samples_leaf=2, min_samples_split=18, n_estimators=100, subsample=0.05), alpha=0.99, learning_rate=0.001, loss=lad, max_depth=9, max_features=0.05, min_samples_leaf=15, min_samples_split=18, n_estimators=100, subsample=0.4)\n",
      "arsinh 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.13740276110358832\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.14262578139672916\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.14262578139672916\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.14262578139672916\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.14262578139672916\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.14568479429851106\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.14568479429851106\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.14568479429851106\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.14568479429851106\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.14568479429851106\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(KBinsDiscretizer(input_matrix, encode=ordinal, n_bins=50, strategy=quantile), bootstrap=True, max_features=0.5, min_samples_leaf=4, min_samples_split=8, n_estimators=100)\n",
      "arsinh 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.14844588123201108\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.1495956501142729\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.16424017973554356\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.17626444152144083\n",
      "\n",
      "Best pipeline: XGBRegressor(SGDRegressor(LassoLarsCV(input_matrix, normalize=True), alpha=0.01, eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate=constant, loss=epsilon_insensitive, penalty=elasticnet, power_t=50.0), learning_rate=0.5, max_depth=3, min_child_weight=13, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.9000000000000001, verbosity=0)\n",
      "cuberoot 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.06610868297807639\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.06610868297807639\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.06867542476641568\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.0716354643428535\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.07274280841008887\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.0778398984644227\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.0778398984644227\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.0778398984644227\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.0778398984644227\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.0778398984644227\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=5, min_child_weight=12, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.8500000000000001, verbosity=0)\n",
      "cuberoot 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.14707204622543327\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.1592765856291382\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.16029502516249988\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.16781695504282915\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.16975520463249744\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.16975520463249744\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.16975520463249744\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.18796847677110312\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.18796847677110312\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.18796847677110312\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(SGDRegressor(GradientBoostingRegressor(input_matrix, alpha=0.85, learning_rate=0.001, loss=quantile, max_depth=8, max_features=0.9500000000000001, min_samples_leaf=19, min_samples_split=6, n_estimators=100, subsample=0.7000000000000001), alpha=0.01, eta0=0.01, fit_intercept=True, l1_ratio=0.0, learning_rate=constant, loss=squared_loss, penalty=elasticnet, power_t=100.0), bootstrap=False, max_features=0.1, min_samples_leaf=9, min_samples_split=20, n_estimators=100)\n",
      "cuberoot 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.15414712388266555\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.15600407107684258\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.15600407107684258\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.15681966528797417\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.15899557939254186\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.1637743166506415\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.16729377360957737\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.16729377360957737\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.16729377360957737\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.16729377360957737\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(Normalizer(input_matrix, norm=l1), bootstrap=True, max_features=0.5, min_samples_leaf=4, min_samples_split=8, n_estimators=100)\n",
      "cuberoot 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.14000734639828488\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.14528802728049944\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.14528802728049944\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.14528802728049944\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.16114890701060053\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.16979638710208972\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.16979638710208972\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.16979638710208972\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.16979638710208972\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.16979638710208972\n",
      "\n",
      "Best pipeline: RandomForestRegressor(Normalizer(input_matrix, norm=l1), bootstrap=True, max_features=0.45, min_samples_leaf=8, min_samples_split=7, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "for key, value in data_transformations.items():\n",
    "    for cluster in filtered_vars.keys():\n",
    "        if cluster != 'all':\n",
    "            print(key, cluster)\n",
    "            cluster_index = feats[feats['cluster_mode']==cluster].index\n",
    "            temp_features = feats.copy()\n",
    "            temp_features.loc[:, ~temp_features.columns.isin(do_not_transform)] = temp_features.loc[:, ~temp_features.columns.isin(do_not_transform)].apply(value[0], axis=1) \n",
    "            lagged_feature = shift_dataset(temp_features.copy(), lag=True, forecast=False, nlag=50, dropna=True,\n",
    "                                          var_lags=vars_to_lag)\n",
    "            lagged_feature_train = lagged_feature.loc[np.intersect1d(cluster_index, lagged_feature.index), filtered_vars[cluster]]\n",
    "            lagged_feature_train = lagged_feature_train.loc[:cutoff_date, :]\n",
    "            lagged_feature_test = lagged_feature.loc[cutoff_date:, filtered_vars[cluster]]\n",
    "            temp_target = to_predict.loc[lagged_feature_train.index].apply(value[0])\n",
    "            tpot_model.fit(lagged_feature_train, temp_target)\n",
    "            tpot_model.export('checkpoints/' + str(int(cluster)) + '_transf_' + key + '_best_model.py')\n",
    "            joblib.dump(tpot_model.fitted_pipeline_, 'models/' + str(cluster) + '_transf_' + key + '_model.joblib')\n",
    "            oos_predictions[str(int(cluster)) + '_transf_' + key] = pd.Series(data=tpot_model.predict(lagged_feature_test), index=lagged_feature_test.index).apply(value[1])\n",
    "            del temp_features, lagged_feature, lagged_feature_train, lagged_feature_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model for all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial hypothesis was that clustering market structure and creating a model for each cluster would improve performance given that a specific model would be made for different distributions. \n",
    "\n",
    "To check if this holds true, we will create an additional model trained on the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.12071817080508569\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.12071817080508569\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.12110870375150125\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.1218100428607282\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.1218100428607282\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.12397649637376836\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.12397649637376836\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.12397649637376836\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.12397649637376836\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.12477542006995652\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(SelectFwe(input_matrix, alpha=0.029), alpha=0.99, learning_rate=0.001, loss=lad, max_depth=9, max_features=0.2, min_samples_leaf=13, min_samples_split=8, n_estimators=100, subsample=0.7500000000000001)\n",
      "arsinh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.12310819534039193\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.12310819534039193\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.12346068754985876\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.12346068754985876\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.12422596892024666\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.12422596892024666\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.12433560006491413\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.12531003565377277\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.1262059879568359\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.1274978221247393\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(StandardScaler(SelectFwe(input_matrix, alpha=0.048)), alpha=0.75, learning_rate=0.001, loss=lad, max_depth=9, max_features=0.2, min_samples_leaf=16, min_samples_split=18, n_estimators=100, subsample=0.4)\n",
      "cuberoot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=275.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.10556322762573167\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.1202716138538257\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.1202716138538257\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.1202716138538257\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.1202716138538257\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.1202716138538257\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.12041377047744233\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.12281671220320015\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.12281671220320015\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.12281671220320015\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(KBinsDiscretizer(input_matrix, encode=ordinal, n_bins=500, strategy=quantile), bootstrap=True, max_features=0.5, min_samples_leaf=18, min_samples_split=8, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "for key, value in data_transformations.items():\n",
    "    print(key)\n",
    "    temp_features = feats.copy()\n",
    "    temp_features.loc[:, ~temp_features.columns.isin(do_not_transform)] = temp_features.loc[:, ~temp_features.columns.isin(do_not_transform)].apply(value[0], axis=1) \n",
    "    lagged_feature = shift_dataset(temp_features.copy(), lag=True, forecast=False, nlag=50, var_lags=vars_to_lag, dropna=True)\n",
    "    lagged_feature_train = lagged_feature.loc[:cutoff_date, filtered_vars['all']]\n",
    "    lagged_feature_test = lagged_feature.loc[cutoff_date:, filtered_vars['all']]\n",
    "    temp_target = to_predict.loc[lagged_feature_train.index].apply(value[0])\n",
    "    tpot_model.fit(lagged_feature_train, temp_target)\n",
    "    tpot_model.export('checkpoints/best_model_all_' + key + '.py')\n",
    "    joblib.dump(tpot_model.fitted_pipeline_, 'models/best_model_all_' + key + '.joblib')\n",
    "    oos_predictions['all_' + key] = pd.Series(data=tpot_model.predict(lagged_feature_test), index=lagged_feature_test.index).apply(value[1])\n",
    "    del lagged_feature, temp_features, lagged_feature_train, lagged_feature_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
